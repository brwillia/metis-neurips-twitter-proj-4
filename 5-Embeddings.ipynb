{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:15:43.964755Z",
     "iopub.status.busy": "2020-11-16T05:15:43.964212Z",
     "iopub.status.idle": "2020-11-16T05:15:46.975392Z",
     "shell.execute_reply": "2020-11-16T05:15:46.974578Z",
     "shell.execute_reply.started": "2020-11-16T05:15:43.964645Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "df = pd.read_pickle(\"./2019_cleaned.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:16:18.383010Z",
     "iopub.status.busy": "2020-11-16T05:16:18.382415Z",
     "iopub.status.idle": "2020-11-16T05:16:18.412803Z",
     "shell.execute_reply": "2020-11-16T05:16:18.411211Z",
     "shell.execute_reply.started": "2020-11-16T05:16:18.382954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>lang</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-04 01:16:24</td>\n",
       "      <td>shinyML</td>\n",
       "      <td>rl for chip design ðŸ™Œ everyoneâ€™s fave game #neu...</td>\n",
       "      <td>1312562178143248384</td>\n",
       "      <td>en</td>\n",
       "      <td>rl for chip design  everyoneâ€™s fave game</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-06-14 03:01:00</td>\n",
       "      <td>KirkDBorne</td>\n",
       "      <td>Analysis of #NeurIPS2019 papers by themes: htt...</td>\n",
       "      <td>1272001061054799872</td>\n",
       "      <td>en</td>\n",
       "      <td>analysis of  papers by themes    â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-06-30 14:14:21</td>\n",
       "      <td>arXiv__ml</td>\n",
       "      <td>RT @Xingyu2017: How should we combine multiple...</td>\n",
       "      <td>1277968719969259520</td>\n",
       "      <td>en</td>\n",
       "      <td>rt  how should we combine multiple auxiliary t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-14 10:48:20</td>\n",
       "      <td>bguedj</td>\n",
       "      <td>A 10-min video about our #NeurIPS2019 paper \"D...</td>\n",
       "      <td>1282990304929488896</td>\n",
       "      <td>en</td>\n",
       "      <td>a min video about our  paper dichotomize and g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-09-18 11:24:30</td>\n",
       "      <td>gorayni</td>\n",
       "      <td>#NeurIPS2019 Bibliometrics\\n\\nTop 5 most cited...</td>\n",
       "      <td>1306917005963005952</td>\n",
       "      <td>en</td>\n",
       "      <td>bibliometrics  top  most cited papers as toda...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date screen_name  \\\n",
       "1 2020-10-04 01:16:24     shinyML   \n",
       "2 2020-06-14 03:01:00  KirkDBorne   \n",
       "3 2020-06-30 14:14:21   arXiv__ml   \n",
       "4 2020-07-14 10:48:20      bguedj   \n",
       "6 2020-09-18 11:24:30     gorayni   \n",
       "\n",
       "                                               tweet             tweet_id  \\\n",
       "1  rl for chip design ðŸ™Œ everyoneâ€™s fave game #neu...  1312562178143248384   \n",
       "2  Analysis of #NeurIPS2019 papers by themes: htt...  1272001061054799872   \n",
       "3  RT @Xingyu2017: How should we combine multiple...  1277968719969259520   \n",
       "4  A 10-min video about our #NeurIPS2019 paper \"D...  1282990304929488896   \n",
       "6  #NeurIPS2019 Bibliometrics\\n\\nTop 5 most cited...  1306917005963005952   \n",
       "\n",
       "  lang                                      cleaned_tweet  \n",
       "1   en         rl for chip design  everyoneâ€™s fave game    \n",
       "2   en  analysis of  papers by themes    â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”   ...  \n",
       "3   en  rt  how should we combine multiple auxiliary t...  \n",
       "4   en  a min video about our  paper dichotomize and g...  \n",
       "6   en   bibliometrics  top  most cited papers as toda...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:16:28.445257Z",
     "iopub.status.busy": "2020-11-16T05:16:28.444791Z",
     "iopub.status.idle": "2020-11-16T05:16:28.449741Z",
     "shell.execute_reply": "2020-11-16T05:16:28.448649Z",
     "shell.execute_reply.started": "2020-11-16T05:16:28.445199Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = df['cleaned_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:16:45.256570Z",
     "iopub.status.busy": "2020-11-16T05:16:45.256213Z",
     "iopub.status.idle": "2020-11-16T05:16:46.315345Z",
     "shell.execute_reply": "2020-11-16T05:16:46.314258Z",
     "shell.execute_reply.started": "2020-11-16T05:16:45.256538Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Document-term matrix: (4718, 142308)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(f\"Dimensions of Document-term matrix: {X.toarray().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:17:00.678436Z",
     "iopub.status.busy": "2020-11-16T05:17:00.678101Z",
     "iopub.status.idle": "2020-11-16T05:17:01.333072Z",
     "shell.execute_reply": "2020-11-16T05:17:01.332338Z",
     "shell.execute_reply.started": "2020-11-16T05:17:00.678406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of Document-term matrix: (4718, 98707)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,3), stop_words='english')\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(f\"Dimensions of Document-term matrix: {X.toarray().shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:17:25.339034Z",
     "iopub.status.busy": "2020-11-16T05:17:25.338432Z",
     "iopub.status.idle": "2020-11-16T05:17:25.646492Z",
     "shell.execute_reply": "2020-11-16T05:17:25.645801Z",
     "shell.execute_reply.started": "2020-11-16T05:17:25.338995Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:17:33.364144Z",
     "iopub.status.busy": "2020-11-16T05:17:33.363812Z",
     "iopub.status.idle": "2020-11-16T05:17:33.703329Z",
     "shell.execute_reply": "2020-11-16T05:17:33.702402Z",
     "shell.execute_reply.started": "2020-11-16T05:17:33.364115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the documents\n",
    "tokenized_docs = [gensim.utils.simple_preprocess(d) for d in corpus]\n",
    "\n",
    "# Create a Gensim Dictionary.  This creates an id to word mapping for everything in our vocbulary\n",
    "# It is NOT the same as the dictionary object in the Python standard library\n",
    "mydict = gensim.corpora.Dictionary()\n",
    "\n",
    "# Create a Gensim Corpus object.  This creates a list of tuples for each document.\n",
    "# The first element of the tuple is the word id, the second is the number of counts\n",
    "mycorpus = [mydict.doc2bow(doc, allow_update=True) for doc in tokenized_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:17:43.087405Z",
     "iopub.status.busy": "2020-11-16T05:17:43.087038Z",
     "iopub.status.idle": "2020-11-16T05:17:43.967060Z",
     "shell.execute_reply": "2020-11-16T05:17:43.965773Z",
     "shell.execute_reply.started": "2020-11-16T05:17:43.087373Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_term_matrix = gensim.matutils.corpus2dense(mycorpus, num_terms=len(mydict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:17:57.519667Z",
     "iopub.status.busy": "2020-11-16T05:17:57.519145Z",
     "iopub.status.idle": "2020-11-16T05:17:58.887185Z",
     "shell.execute_reply": "2020-11-16T05:17:58.886225Z",
     "shell.execute_reply.started": "2020-11-16T05:17:57.519609Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_term_matrix\n",
    "tfidf = gensim.models.TfidfModel(mycorpus)\n",
    "tfidf_matrix = gensim.matutils.corpus2dense(tfidf[mycorpus], num_terms=len(mydict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:18:04.011383Z",
     "iopub.status.busy": "2020-11-16T05:18:04.011031Z",
     "iopub.status.idle": "2020-11-16T05:18:04.018081Z",
     "shell.execute_reply": "2020-11-16T05:18:04.016729Z",
     "shell.execute_reply.started": "2020-11-16T05:18:04.011352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46769   , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.31106466, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.32098472, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.3217932 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.3217932 ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.3217932 ]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:18:26.502748Z",
     "iopub.status.busy": "2020-11-16T05:18:26.502363Z",
     "iopub.status.idle": "2020-11-16T05:18:26.705703Z",
     "shell.execute_reply": "2020-11-16T05:18:26.705124Z",
     "shell.execute_reply.started": "2020-11-16T05:18:26.502713Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenized_docs = [gensim.utils.simple_preprocess(d) for d in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:18:38.224117Z",
     "iopub.status.busy": "2020-11-16T05:18:38.223781Z",
     "iopub.status.idle": "2020-11-16T05:18:41.032231Z",
     "shell.execute_reply": "2020-11-16T05:18:41.030905Z",
     "shell.execute_reply.started": "2020-11-16T05:18:38.224090Z"
    }
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(tokenized_docs, size=10, window=2,min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:19:30.023861Z",
     "iopub.status.busy": "2020-11-16T05:19:30.023570Z",
     "iopub.status.idle": "2020-11-16T05:19:30.041933Z",
     "shell.execute_reply": "2020-11-16T05:19:30.037527Z",
     "shell.execute_reply.started": "2020-11-16T05:19:30.023835Z"
    }
   },
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-16T05:23:10.570584Z",
     "iopub.status.busy": "2020-11-16T05:23:10.570249Z",
     "iopub.status.idle": "2020-11-16T05:47:22.972142Z",
     "shell.execute_reply": "2020-11-16T05:47:22.970999Z",
     "shell.execute_reply.started": "2020-11-16T05:23:10.570554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    }
   ],
   "source": [
    "google_vec_file = './GoogleNews-vectors-negative300.bin'\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
